---
title: "MTH404 R Project"
author: "Mustafif Khan"
output:
    pdf_document: default
    word_document: default
---

# Loading Required Packages
Before the dataset can be analyzed, the following packages must be imported:
```{r}
library(tidyverse)
library(corrplot)
library(ggplot2)
library(lubridate)
library(gridExtra)
library(caTools)
library(dplyr)
```

# Reading the Training and Test Data
From the kaggle competition, we are provided the CSV data for training and testing,
and the dataset is imported like the following:
```{r}
train_data <- read.csv("train.csv")
test_data <- read.csv("test.csv")
head(train_data)
head(test_data)
```

We will now convert all the character columns to factors as shown below:
```{r}
train_data <- as.data.frame(unclass(train_data), stringsAsFactors = TRUE)
test_data <- as.data.frame(unclass(test_data), stringsAsFactors = TRUE)
```

With the data converted, we can check if we are missing values in our training data:
```{r}
# get the missing training values
missing_training_values <- sapply(train_data, function(x) sum(is.na(x)))
# create a data frame with column names and missing values
mtv_df <- data.frame(column = names(missing_training_values),
                     missing_values = missing_training_values)
mtv_df
```
As you can notice there are data in this dataset that contains large amounts of missing values, such
as columns like `PoolQC`, `Fence`, etc. We will be removing the columns with missing values like the following:
```{r}
data.train <- subset(train_data, select = -c(Id, LotFrontage, Alley, MasVnrType, MasVnrArea, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, Electrical, FireplaceQu, GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond, PoolQC, Fence, MiscFeature))
head(data.train)
```

Now it would be good to also remove these columns from our testing data as well:
```{r}
data.test <- subset(test_data, select = -c(Id, LotFrontage, Alley, MasVnrType, MasVnrArea, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, Electrical, FireplaceQu, GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond, PoolQC, Fence, MiscFeature))
head(data.test)
```

# Analysis of the Train Data
Before we create a model to analyze our training data, we will need to look at the structure of our different columns
using the `str()` function and get a summary of our training data.

```{r}
str(train_data)
summary(train_data)
```

## Visualizing the Data

To check the distribution of the target variable `SalePrice`, we will look at a boxplot and a histogram as
shown below:

```{r}
boxplot(data.train$SalePrice)
hist(data.train$SalePrice)
```

## Correlation with `SalePrice`

To analyze the data, we will need to create a model using the `lm()` function, where will be using
`SalesPrice` to compare our other fields. Using the model, we can use `summary()` to find better information
about our model, such as $R^2$.
```{r}
model <- lm(SalePrice ~., data=data.train)
summary(model)
```

With the summary we can see that we have $R^2 = 0.9206$, and we can make some of the following interpretations when
comparing `SalesPrice` with some of the most significant fields marked with `***`:
Whenever the sales price increases by one dollar...

- `PoolArea`: the pool's area will increase by $71.39 m^2$.
- `OverallQual`: the overall quality will increase by $\$7995$.
- `OverallCond`: the overall condition will increase by $\$5378$.
- `LotArea`: the lot's area will increase by $0.702 m^2$.

For a better visual we will be plotting graphs between the sale price and the significant fields mentioned.
```{r}
# Plot between PoolArea and SalePrice
ggplot(data = data.train, aes(x = PoolArea, y = SalePrice)) +
  geom_jitter() +  geom_smooth(method = "lm", se = FALSE) +
  labs(title="Scatter plot of Pool Area and Sales Price", x="Area (m^2)",y="Price ($)")

# Plot between Overall Quality and SalePrice
ggplot(data = data.train, aes(x = OverallQual, y = SalePrice)) +
  geom_jitter() +  geom_smooth(method = "lm", se = FALSE) +
  labs(title="Plot of Overall Quality and Sales Price", x="Quality Value",y="Price ($)")

# Plot between Overall Condition and SalePrice
ggplot(data = data.train, aes(x = OverallCond, y = SalePrice)) +
  geom_jitter() +  geom_smooth(method = "lm", se = FALSE) +
  labs(title="Plot of Overall Condition and Sales Price", x="Condition Value",y="Price ($)")

# plot between Lot Area and SalePrice
ggplot(data = data.train, aes(x = LotArea, y = SalePrice)) +
  geom_jitter() +  geom_smooth(method = "lm", se = FALSE) +
  labs(title="Plot of Lot Area and Sales Price", x="Lot Area (m^2)",y="Price ($)")
```

While our plots show a great visualization between the correlation of the Price and the mentioned significant fields, it is still
a small portion of the full plate of data we have. To gain a better insight to our complete palette, we need to look into a correlation
plot of all the independent numerical variables and their association with our dependent variable sales price.

```{r}
# get all the numerical variables
data.num <- data.train %>% dplyr::select(where(is.numeric))
# get the correlation data
data.cor <- data.frame(data.num[, 3:21])
correlation <- cor(data.cor)
# display the correlation
correlation
par(mfrow=c(1,1))
# plot the correlation
corrplot(correlation, method = "color")
```

# Outliers

Our data is quite accurate, but to see the effects outliers may have with `SalePrice`, we will try to plot the data
with and without outliers to see the effect it has on us. First we need to extract outliers from the data and obtain the
data without the outliers we'll find.

```{r}
outliers = boxplot(data.train$SalePrice, plot = FALSE)$out
outliers_data <- data.train[which(data.train$SalePrice %in% outliers),]
no_out_train <- data.train[-which(data.train$SalePrice %in% outliers),]
```

Now we can plot our data with outliers and without to see the effect it has on our data:

```{r}
par(mfrow=c(1,2))
# plot the data with the outliers
plot(data.train$LotArea, data.train$SalePrice, main = "With Outliers",
     xlab = "Lot Area", ylab = "Sale Price" , pch="*", col = "blue", cex = 2)
abline(lm(SalePrice ~ LotArea, data=data.train), col = "magenta", lwd = 3, lty = 2)
plot(no_out_train$LotArea, no_out_train$SalePrice, main="Outliers removed",
     xlab="Lot Area", ylab="Sale Price", pch="*", col="red", cex=2)
abline(lm(SalePrice ~ LotArea, data=no_out_train), col="blue", lwd=3, lty=2)
```

As you can see, we are able to concetrate the relationship between `SalePrice` and `LotArea` by removing the outliers and find that
most of the values for `SalePrice` range from around $\$50 000 - \$350 000$.

# Accuracy of the Model

We will determine the accuracy of the training data model by the following:
```{r}
# predicted values
pred <- model$fitted.values
tally_table <- data.frame(actual=data.train$SalePrice, predicted=pred)

mape <- mean(abs(tally_table$actual-tally_table$predicted)/tally_table$actual)
accuracy <- 1-mape
accuracy
```
**We can see that the accuracy of our training data model is ** \textbf{$91.51\%$}

## Accuracy of the Model on Test Data
```{r}

```